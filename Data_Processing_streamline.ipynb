{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e8492d-9df0-4cd9-8db3-698a4dc1c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "BASE_DIR=\"/Users/dannyyu/Desktop/AI_Trader/data\"\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'INTC', 'AMD', 'IBM']\n",
    "START_DATE = \"2022-01-01\"\n",
    "END_DATE = datetime.datetime.today()\n",
    "\n",
    "##create the folders\n",
    "os.makedirs(os.path.join(BASE_DIR, \"prices\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, \"fundamentals\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, \"metadata\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843a50b3-bcf9-4ede-8f67-7fb04804efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the most recent available closing price on or before target_date\n",
    "by checking historical data within the past `lookback_days`.\n",
    "\"\"\"\n",
    "def get_closest_price(ticker_obj, target_date, lookback_days=3):\n",
    "    try:\n",
    "        start_date = target_date - pd.Timedelta(days=lookback_days)\n",
    "        end_date = target_date + pd.Timedelta(days=1)\n",
    "\n",
    "        hist = ticker_obj.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if not hist.empty:\n",
    "            last_row = hist.iloc[-1]\n",
    "            timestamp_str = hist.index[-1].strftime(\"%Y-%m-%d\")\n",
    "           # print(\"Data retrieved on date \"+timestamp_str)\n",
    "            return last_row['Close']\n",
    "        else:\n",
    "            print(f\"No price data found for {ticker_obj.ticker} between {start_date.date()} and {end_date.date()}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price for {ticker_obj.ticker} near {target_date.date()}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c037455c-9d47-429e-bd18-7247fdbbd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamentals_history(ticker, years=3):\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    info = ticker_obj.info\n",
    "\n",
    "    # Get quarterly and annual statements\n",
    "    q_income_stmt = ticker_obj.quarterly_financials\n",
    "    q_balance_sheet = ticker_obj.quarterly_balance_sheet\n",
    "    q_cashflow_stmt = ticker_obj.quarterly_cashflow\n",
    "\n",
    "    y_income_stmt = ticker_obj.financials\n",
    "    y_balance_sheet = ticker_obj.balance_sheet\n",
    "    y_cashflow_stmt = ticker_obj.cashflow\n",
    "\n",
    "    # Initialize\n",
    "    fundamentals = []\n",
    "\n",
    "    # Helper to extract data row by row from financials\n",
    "    def extract_fundamentals(date, is_quarterly=True):\n",
    "        try:\n",
    "            stmt_src = \"quarterly\" if is_quarterly else \"yearly\"\n",
    "            inc = q_income_stmt if is_quarterly else y_income_stmt\n",
    "            bal = q_balance_sheet if is_quarterly else y_balance_sheet\n",
    "            cf  = q_cashflow_stmt if is_quarterly else y_cashflow_stmt\n",
    "\n",
    "            revenue = inc.loc[\"Total Revenue\", date]\n",
    "            gross_profit = inc.loc[\"Gross Profit\", date]\n",
    "            ebitda = inc.loc[\"EBITDA\", date]\n",
    "            net_income = inc.loc[\"Net Income\", date]\n",
    "\n",
    "            operating_cashflow = cf.loc[\"Operating Cash Flow\", date]\n",
    "            total_equity = bal.loc[\"Common Stock Equity\", date]\n",
    "            total_debt = bal.loc[\"Total Debt\", date]\n",
    "\n",
    "            roe = net_income / total_equity if total_equity else None\n",
    "            debt_to_equity = (total_debt / total_equity)*100 if total_equity else None\n",
    "            operating_margin = net_income / revenue if revenue else None\n",
    "\n",
    "            diluted_eps = inc.loc[\"Diluted EPS\", date]\n",
    "            hist_price = get_closest_price(ticker_obj, date)\n",
    "            pe_ratio = (hist_price / diluted_eps) if hist_price and diluted_eps else info.get(\"trailingPE\", None)\n",
    "\n",
    "            return {\n",
    "                \"Date\": date.strftime('%Y-%m-%d'),\n",
    "                \"DilutedEPS\": diluted_eps,\n",
    "                \"PE\": pe_ratio,\n",
    "                \"Revenue\": revenue,\n",
    "                \"CashFlow\": operating_cashflow,\n",
    "                \"EBITDA\": ebitda,\n",
    "                \"GrossProfit\": gross_profit,\n",
    "                \"OperatingMargin\": round(operating_margin, 8),\n",
    "                \"ROE\": round(roe, 3),\n",
    "                \"DebtToEquity\": round(debt_to_equity, 5),\n",
    "                \"Source\": stmt_src\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker} for {date.date()} [{stmt_src}]: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Include most recent static values\n",
    "    fundamentals.append({\n",
    "        \"Date\": pd.Timestamp.today().strftime('%Y-%m-%d'),\n",
    "        \"DilutedEPS\": info.get(\"trailingEps\", None),\n",
    "        \"PE\": info.get(\"trailingPE\", None),\n",
    "        \"Revenue\": info.get(\"totalRevenue\", None),\n",
    "        \"CashFlow\": info.get(\"operatingCashflow\", None),\n",
    "        \"EBITDA\": info.get(\"ebitda\", None),\n",
    "        \"GrossProfit\": info.get(\"grossProfits\", None),\n",
    "        \"OperatingMargin\": info.get(\"operatingMargins\", None),\n",
    "        \"ROE\": info.get(\"returnOnEquity\", None),\n",
    "        \"DebtToEquity\": info.get(\"debtToEquity\", None),\n",
    "        \"Source\": \"info\"\n",
    "    })\n",
    "\n",
    "    # Add quarterly reports (within last ~15 months)\n",
    "    q_dates = q_income_stmt.columns.intersection(q_balance_sheet.columns).intersection(q_cashflow_stmt.columns)\n",
    "    for q_date in q_dates:\n",
    "        if (pd.Timestamp.today() - q_date).days <= 450:\n",
    "            row = extract_fundamentals(q_date, is_quarterly=True)\n",
    "            if row:\n",
    "                fundamentals.append(row)\n",
    "\n",
    "    # Add yearly reports, excluding any years already covered\n",
    "    y_dates = y_income_stmt.columns.intersection(y_balance_sheet.columns).intersection(y_cashflow_stmt.columns)\n",
    "    included_years = {pd.to_datetime(f[\"Date\"]).year for f in fundamentals}\n",
    "\n",
    "    for y_date in y_dates:\n",
    "        if y_date.year in included_years or pd.Timestamp.today().year - y_date.year > years:\n",
    "            continue\n",
    "        row = extract_fundamentals(y_date, is_quarterly=False)\n",
    "        if row:\n",
    "            fundamentals.append(row)\n",
    "\n",
    "    return pd.DataFrame(fundamentals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f0fbd6-b492-4404-a9ec-21cd8c8ab1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_CSV_File(ticker,folderName):\n",
    "    dir = BASE_DIR+\"/\"+folderName+\"/\"+ticker+\"_\"+folderName+\".csv\"\n",
    "    table= pd.read_csv(dir,index_col=0,low_memory=False)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8cc92c-89c4-4963-9961-cc12e781e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the table for historical price and fundamental indicators, indexed on Date\n",
    "#merged on Year so that all historical price data are matched to the fundamental indicators of the same year\n",
    "def merge_table(price, fund):\n",
    "    price = price.copy()\n",
    "    price.index = pd.to_datetime(price.index, utc=True)\n",
    "    fund = fund.copy()\n",
    "    fund.index = pd.to_datetime(fund.index, utc=True)\n",
    "\n",
    "         # Mark report source date\n",
    "    fund[\"FundamentalReportDate\"] = fund.index\n",
    "    \n",
    "    # Reset both so that Date is a column\n",
    "\n",
    "    price = price.reset_index()\n",
    "    fund = fund.reset_index()\n",
    "    \n",
    "    # Then proceed as usual\n",
    "    #merged = pd.merge(price, fund, on=\"Date\", how=\"left\")\n",
    "\n",
    "    merged = pd.concat([price, fund], ignore_index=True, sort=False)\n",
    "\n",
    "    merged = merged.sort_values(\"Date\", ascending=False)\n",
    "\n",
    "    # Get list of fundamental columns (excluding 'Date' and 'FundamentalReportDate')\n",
    "    fund_cols = fund.columns.drop([\"Date\", \"FundamentalReportDate\"], errors='ignore')\n",
    "    # Backward fill fundamental data\n",
    "    merged[fund_cols] = merged[fund_cols].bfill()\n",
    "    merged[\"FundamentalReportDate\"] = merged[\"FundamentalReportDate\"].bfill()\n",
    "\n",
    "    merged[fund_cols] = merged[fund_cols].ffill()\n",
    "    merged[\"FundamentalReportDate\"] = merged[\"FundamentalReportDate\"].ffill()\n",
    "\n",
    "    # Sort back to chronological\n",
    "    merged = merged.sort_values(\"Date\")\n",
    "\n",
    "    # Add Year column\n",
    "    merged[\"Year\"] = merged[\"Date\"].dt.year\n",
    "    merged = merged.dropna(subset=[\"Close\"])\n",
    "    merged = merged.drop(columns=[\"Source\",\"FundamentalReportDate\"], errors=\"ignore\")\n",
    "\n",
    "    # Set Date as index\n",
    "    merged.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd02df7b-114d-42d9-9178-5558aba94ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_divident(metadata):\n",
    "    metadata[\"Year\"] = pd.to_datetime(metadata.index, utc=True).year #pd.to_datetime(metadata['Date'], utc=True).dt.year\n",
    "    dividend_by_year = metadata.groupby('Year')['Dividends'].apply(lambda x: int((x > 0).any()))\n",
    "    metadata['HasDividend'] = metadata['Year'].map(dividend_by_year)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c117cb9a-327a-4a34-a9e4-8428b23542bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(table):\n",
    "    total_rows = len(table)\n",
    "    hasMissing=False\n",
    "    print(\"Analyzing \"+table.iloc[1][\"Company\"])\n",
    "    for column in table.columns:\n",
    "        num_missing = table[column].isna().sum()\n",
    "        if num_missing == 0:\n",
    "            #print(f\"ðŸ“Š '{column}': no missing values\")\n",
    "            continue  # skip columns with no missing data\n",
    "        else:\n",
    "            hasMissing=True\n",
    "        percent_missing = 100 * num_missing / total_rows\n",
    "        print(f\"ðŸ“Š '{column}': {num_missing} missing ({percent_missing:.2f}%)\")\n",
    "    if not hasMissing:\n",
    "        print(table.iloc[1][\"Company\"] + \" has no missing values\")\n",
    "    return hasMissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a371f169-b516-4224-8195-6753bb91abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shares_outstanding(table, year):\n",
    "    ticker_symbol = table['Company'].iloc[0]\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "    current_year = datetime.datetime.now().year\n",
    "    if year == current_year:\n",
    "        shares = ticker.info.get('sharesOutstanding', None)\n",
    "        return round(shares, 0)\n",
    "    else:\n",
    "        income = ticker.financials\n",
    "        income.columns = pd.to_datetime(income.columns)\n",
    "        matching_cols = [col for col in income.columns if col.year == year]\n",
    "        col = matching_cols[0]\n",
    "        net_income = income.at['Net Income', col]\n",
    "        row = table[table[\"Year\"] == year]\n",
    "        eps = row['DilutedEPS'].iloc[0]\n",
    "        estimated_shares = net_income / eps\n",
    "        return round(estimated_shares,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fdd777-e2b4-4ae0-8755-530511e42e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds per-share normalized versions of Revenue, CashFlow, EBITDA, and GrossProfit using estimated shares outstanding for each row.\n",
    "def normalize_per_share(table):\n",
    "    table['Revenue_perShare'] = None\n",
    "    table['CashFlow_perShare'] = None\n",
    "    table['EBITDA_perShare'] = None\n",
    "    table['GrossProfit_perShare'] = None\n",
    "    \n",
    "    for year in table[\"Year\"].unique():\n",
    "        mask = (table['Year'] == year)\n",
    "        row_subset = table[mask]\n",
    "        shares = get_shares_outstanding(table, year)\n",
    "\n",
    "        table.loc[mask, 'Revenue_perShare']     = table.loc[mask, 'Revenue']     / shares\n",
    "        table.loc[mask, 'CashFlow_perShare']    = table.loc[mask, 'CashFlow']    / shares\n",
    "        table.loc[mask, 'EBITDA_perShare']      = table.loc[mask, 'EBITDA']      / shares\n",
    "        table.loc[mask, 'GrossProfit_perShare'] = table.loc[mask, 'GrossProfit'] / shares\n",
    "\n",
    "    per_share_cols = ['Revenue_perShare', 'CashFlow_perShare', 'EBITDA_perShare', 'GrossProfit_perShare']\n",
    "    table[per_share_cols] = table[per_share_cols].astype(float).round(5)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b585ded7-ce46-43ae-bd9d-8f8e72942bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_metadata_files(folderName=\"metadata\"):\n",
    "    combined=[]\n",
    "    for file in os.listdir(os.path.join(BASE_DIR, folderName)):\n",
    "        if file.endswith(\"_metadata.csv\") and file!= \"MASTER_metadata.csv\":\n",
    "            ticker = file.split(\"_\")[0]\n",
    "            df = read_CSV_File(ticker, folderName)\n",
    "            combined.append(df)\n",
    "\n",
    "    if combined:\n",
    "        master_df = pd.concat(combined, ignore_index=False)\n",
    "        return master_df\n",
    "    else:\n",
    "        print(\"error occured\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96b191e-48a7-4866-a05b-59159a381c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentile(table):\n",
    "    indicators = [\"OperatingMargin\",\"ROE\",\"DebtToEquity\",\"Revenue_perShare\",\"CashFlow_perShare\",\"EBITDA_perShare\",\"GrossProfit_perShare\"]\n",
    "    for indicator in indicators:\n",
    "        table[f\"{indicator}_Pct\"]=table.groupby('Year')[indicator].rank(pct=True)\n",
    "        table[f\"{indicator}_Pct\"]=table[f\"{indicator}_Pct\"].round(4)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724782ee-1e8c-4659-8ac3-bd5586454842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n",
      "Fetching data for MSFT...\n",
      "Fetching data for GOOGL...\n",
      "Fetching data for AMZN...\n",
      "Fetching data for META...\n",
      "Fetching data for NVDA...\n",
      "Fetching data for TSLA...\n",
      "Fetching data for INTC...\n",
      "Fetching data for AMD...\n",
      "Fetching data for IBM...\n",
      "Preliminary data collection complete!\n"
     ]
    }
   ],
   "source": [
    "## Preliminary Data Collection\n",
    "meta_data = []\n",
    "for ticker in TICKERS:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    stock = yf.Ticker(ticker)\n",
    "\n",
    "    # --- Prices ---\n",
    "    df_price = stock.history(start=START_DATE, end=END_DATE,interval=\"1d\")\n",
    "    df_price.reset_index(inplace=True)\n",
    "    df_price.to_csv(os.path.join(BASE_DIR, \"prices\", f\"{ticker}_prices.csv\"), index=False)\n",
    "\n",
    "    # --- Fundamentals ---\n",
    "    df_fund = get_fundamentals_history(ticker)\n",
    "    df_fund.to_csv(os.path.join(BASE_DIR, \"fundamentals\", f\"{ticker}_fundamentals.csv\"), index=False)\n",
    "\n",
    "    \n",
    "    # --- Metadata for overview ---\n",
    "    meta_data.append({\n",
    "        \"Ticker\": ticker,\n",
    "        \"Name\": stock.info.get(\"shortName\", \"\"),\n",
    "        \"Sector\": stock.info.get(\"sector\", \"\")\n",
    "    })\n",
    "\n",
    "# === SAVE COMPANY LIST ===\n",
    "df_meta = pd.DataFrame(meta_data)\n",
    "df_meta.to_csv(os.path.join(BASE_DIR, \"metadata\", \"company_list.csv\"), index=False)   \n",
    "\n",
    "print(\"Preliminary data collection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b61ac180-d787-4861-bd0f-820fb5eb03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in TICKERS:\n",
    "    fund=read_CSV_File(ticker,\"fundamentals\")\n",
    "    price=read_CSV_File(ticker,\"prices\")\n",
    "    merged=merge_table(price,fund)\n",
    "    merged[\"Company\"]=ticker\n",
    "    merged.to_csv(os.path.join(BASE_DIR, \"metadata\", f\"{ticker}_metadata.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb293d4-efc2-47b3-b4b3-44759a4d2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimating the missing values for Diluted EPS and the PE ratio for IBM\n",
    "#estimate the EPS for 2024 using the currently shares outstanding as a proxy\n",
    "ibm=read_CSV_File(\"IBM\",\"metadata\")\n",
    "ibm_ticker= yf.Ticker(\"IBM\")\n",
    "ibm_fin=ibm_ticker.financials\n",
    "net_income = ibm_fin[\"2024-12-31\"][\"Net Income\"]\n",
    "shares_outstanding = ibm_ticker.info.get(\"sharesOutstanding\", None)\n",
    "eps_estimate=net_income / shares_outstanding\n",
    "# Estimating the PE ratio for 2024 using the EPS estimation from the previous step\n",
    "hist_price=get_closest_price(ibm_ticker, pd.to_datetime(\"2024-12-31\"))\n",
    "pe_ratio = hist_price / eps_estimate\n",
    "\n",
    "ibm['DilutedEPS'] =ibm['DilutedEPS'].fillna(eps_estimate)\n",
    "ibm[\"DilutedEPS\"] = ibm[\"DilutedEPS\"].round(2)\n",
    "ibm['PE'] = ibm['PE'].fillna(pe_ratio)\n",
    "ibm['PE'] = ibm['PE'].round(5)\n",
    "ibm.to_csv(os.path.join(BASE_DIR, \"metadata\",\"IBM_metadata.csv\"), index=True)\n",
    "\n",
    "\n",
    "## estimate the missing PE ratio for INTC using today's price\n",
    "intc=read_CSV_File(\"INTC\",\"metadata\")\n",
    "intc_ticker= yf.Ticker(\"INTC\")\n",
    "price=intc_ticker.history(period=\"1d\")[\"Close\"].iloc[-1]\n",
    "eps=intc.iloc[-1][\"DilutedEPS\"]\n",
    "pe=price/eps\n",
    "intc[\"PE\"]=intc[\"PE\"].fillna(pe)\n",
    "intc['PE'] = intc['PE'].round(5)\n",
    "intc.to_csv(os.path.join(BASE_DIR, \"metadata\",\"INTC_metadata.csv\"), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d06f770a-d5d8-4366-a795-2c5a599a9594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing AAPL\n",
      "AAPL has no missing values\n",
      "Analyzing MSFT\n",
      "MSFT has no missing values\n",
      "Analyzing GOOGL\n",
      "GOOGL has no missing values\n",
      "Analyzing AMZN\n",
      "AMZN has no missing values\n",
      "Analyzing META\n",
      "META has no missing values\n",
      "Analyzing NVDA\n",
      "NVDA has no missing values\n",
      "Analyzing TSLA\n",
      "TSLA has no missing values\n",
      "Analyzing INTC\n",
      "INTC has no missing values\n",
      "Analyzing AMD\n",
      "AMD has no missing values\n",
      "Analyzing IBM\n",
      "IBM has no missing values\n"
     ]
    }
   ],
   "source": [
    "for ticker in TICKERS:\n",
    "    table=read_CSV_File(ticker,\"metadata\")\n",
    "    table=has_divident(table)\n",
    "    table[\"DebtToEquity\"]=table[\"DebtToEquity\"].round(3)\n",
    "    table[\"PE\"]=table[\"PE\"].round(6)\n",
    "    table[\"ROE\"]=table[\"ROE\"].round(3)\n",
    "    missing_value=missing_values(table)\n",
    "    table=normalize_per_share(table)\n",
    "    table.to_csv(os.path.join(BASE_DIR, \"metadata\", f\"{ticker}_metadata.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f09f19-fa5e-4157-a730-1b82a2390025",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = combine_metadata_files()\n",
    "master=compute_percentile(master)\n",
    "master.to_csv(os.path.join(BASE_DIR, \"metadata\", \"MASTER_metadata.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fa3ad-7c16-4e0b-9f70-1b9606e6831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a708f2a-f5ce-43bd-91fc-eda1cbb651d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI_Trader)",
   "language": "python",
   "name": "ai_trader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
